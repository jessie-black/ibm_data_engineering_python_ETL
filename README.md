# ibm_data_engineering_python_ETL
Python project for IBM's Data Engineering Certificate, course #3
Link to Jupyter Notebook <a href ="https://eu-de.dataplatform.cloud.ibm.com/analytics/notebooks/v2/38fe7a81-b260-46b4-9a59-6d405a97aa90/view?access_token=7171684714328e7f499a48663618b478da13f261763b2805af5ab68d1499b932">here</a>

## Tools Used 
- Python
- Jupyter Notebooks
- IBM Watson Studio
- Pandas 

## Project Tasks
- Collect data using APIs
- Collect data using webscraping.
- Download files to process.    
- Read csv, xml and json file types.
- Extract data from the above file types.
- Transform data.
- Use the built in logging module.
- Save the transformed data in a ready-to-load format which data engineers can use to load the data.

## Skills learned/practiced
Crafting functions to extract data from .json source into Pandas dataframe, transform columns, and load into .csv file for storage as well as logging functions for the entire ETL process.

## Most challenging aspect
Debugging inside of Jupyter notebook is a bit awkward and took some getting used to - I ended up using empty cells to test and craft code segments before consolidating into finished functions.
